import streamlit as st
import os
import glob
import json
from datetime import datetime
import config
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from utils import file_manager, state_manager, context_manager, llm_client, text_analyzer, reference_manager, extractor
from utils import smart_extractor, info_panel

# Page Config
st.set_page_config(
    page_title="é•‡å¦–ç‹±åˆ›ä½œå¼•æ“",
    layout="wide",
    initial_sidebar_state="collapsed" # é»˜è®¤æ”¶èµ·ä¾§è¾¹æ 
)

# Custom Global CSS
st.markdown("""
    <style>
    /* å…¨å±€èƒŒæ™¯ */
    .stApp {
        background-color: #0e1117;
    }
    
    /* ç»Ÿä¸€æ–‡å­—æ ·å¼ */
    html, body, [class*="css"] {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    
    /* æ•°å€¼é«˜äº® (æ€æˆ®ç‚¹ç­‰) */
    .killing-points, .highlight-val {
        color: #2ecc71 !important;
        font-weight: bold;
        text-shadow: 0 0 8px rgba(46, 204, 113, 0.4);
    }
    
    /* åˆ†éš”çº¿æ ·å¼ */
    hr {
        margin: 1rem 0 !important;
        border-color: rgba(139, 0, 0, 0.3) !important;
    }
    
    /* å®¹å™¨é—´è·ä¼˜åŒ– */
    .block-container {
        padding-top: 2rem !important;
        padding-bottom: 2rem !important;
    }
    </style>
""", unsafe_allow_html=True)

# Initialize Session State
if "messages_settings" not in st.session_state:
    st.session_state.messages_settings = []
if "messages_outline" not in st.session_state:
    st.session_state.messages_outline = []
if "current_chapter_content" not in st.session_state:
    st.session_state.current_chapter_content = ""
if "current_nav_mode" not in st.session_state:
    st.session_state.current_nav_mode = "åˆå§‹åŒ–"

# --- TOP: DASHBOARD ---
info_panel.render_dashboard()

# --- MIDDLE: NAVIGATION ---
nav_options = ["åˆå§‹åŒ–", "æ¢è®¨è®¾å®š", "æ¢è®¨ç»†çº²", "ç»­å†™æ­£æ–‡", "æ”¹æ–‡ä¸å†²çªæç¤º"]

# å¤„ç†å¤–éƒ¨è·³è½¬
if "app_mode_switch" in st.session_state:
    st.session_state.current_nav_mode = st.session_state.pop("app_mode_switch")

# æ°´å¹³å¯¼èˆª
app_mode = st.radio(
    "åŠŸèƒ½è°ƒåº¦å¯¼èˆª", 
    nav_options, 
    index=nav_options.index(st.session_state.current_nav_mode), 
    horizontal=True,
    label_visibility="collapsed"
)
st.session_state.current_nav_mode = app_mode

st.divider()

# Sidebar (Keep only configuration)
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # API Configuration Section
    st.subheader("ğŸ¤– å¤§æ¨¡å‹é…ç½®")
    st.info("ğŸ’¡ ç³»ç»Ÿå·²åˆå¹¶ä¸ºç»Ÿä¸€ OpenAI å…¼å®¹æ¨¡å¼ï¼Œæ”¯æŒ NewAPI, SiliconFlow, å…¬å¸å†…éƒ¨å¹³å°ç­‰ã€‚")
    
    # åˆå§‹åŒ– session_state ä¸­çš„é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "api_base_url" not in st.session_state:
        st.session_state.api_base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:11434/v1")
    if "api_key" not in st.session_state:
        st.session_state.api_key = os.getenv("OPENAI_API_KEY", "")
    if "model_name" not in st.session_state:
        st.session_state.model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-3.5-turbo")

    # è¾“å…¥æ¡†ï¼šBase URL
    base_url = st.text_input(
        "API æ¥å£åœ°å€ (Base URL)", 
        value=st.session_state.api_base_url,
        placeholder="https://api.openai.com/v1"
    )
    st.session_state.api_base_url = base_url
    os.environ["OPENAI_BASE_URL"] = base_url
    
    # è¾“å…¥æ¡†ï¼šAPI Key
    api_key = st.text_input(
        "API å¯†é’¥ (API Key)", 
        value=st.session_state.api_key,
        type="password"
    )
    st.session_state.api_key = api_key
    os.environ["OPENAI_API_KEY"] = api_key
    
    # è¾“å…¥æ¡†ï¼šæ¨¡å‹åç§°
    model_name = st.text_input(
        "ä½¿ç”¨çš„æ¨¡å‹åç§°", 
        value=st.session_state.model_name
    )
    st.session_state.model_name = model_name
    st.session_state["DEFAULT_MODEL_NAME"] = model_name
    os.environ["OPENAI_MODEL_NAME"] = model_name

    # Configuration Status
    st.divider()
    if st.session_state.api_key:
        st.success("âœ… API å·²é…ç½®")
        st.caption(f"å½“å‰æ¨¡å‹: {st.session_state.model_name}")
    else:
        st.warning("âš ï¸ è¯·é…ç½® API å¯†é’¥")


# ==================== è¾…åŠ©å‡½æ•° V2 ====================

def _save_with_style_analysis_v2(chapter_title, final_content, original_content):
    if not chapter_title.endswith(".txt"):
        chapter_title += ".txt"
    save_path = os.path.join(config.DIR_BODY, chapter_title)
    
    # ä¿å­˜æ–°å†…å®¹
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(final_content)
    
    # æ‰§è¡Œé£æ ¼åˆ†æ
    with st.spinner("æ­£åœ¨åˆ†ææ‚¨çš„å†™ä½œé£æ ¼..."):
        try:
            from utils.style_analyzer import StyleAnalyzer, StyleManager
            analyzer = StyleAnalyzer()
            manager = StyleManager()
            scene_type = analyzer.classify_scene(final_content)
            style_features = analyzer.analyze_modifications(original_content, final_content)
            manager.save_style_profile(scene_type, style_features)
            st.success(f"âœ… é£æ ¼åˆ†æå®Œæˆï¼å·²å­¦ä¹ æ‚¨çš„{scene_type}åœºæ™¯ä¿®ç¨¿ä¹ æƒ¯")
        except Exception as e:
            st.warning(f"é£æ ¼åˆ†æå¤±è´¥ï¼š{str(e)}")
    
    st.success(f"âœ… ç« èŠ‚å·²ä¿å­˜: {chapter_title}")
    st.session_state.generated_chapter = final_content
    st.session_state.pop("ai_draft", None)
    st.rerun()

def _save_with_full_features_v2(chapter_title, final_content, original_content):
    if not chapter_title.endswith(".txt"):
        chapter_title += ".txt"
    save_path = os.path.join(config.DIR_BODY, chapter_title)
    
    # ä¿å­˜
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write(final_content)
    
    # 1. é£æ ¼åˆ†æ
    try:
        from utils.style_analyzer import StyleAnalyzer, StyleManager
        analyzer = StyleAnalyzer()
        manager = StyleManager()
        scene_type = analyzer.classify_scene(final_content)
        style_features = analyzer.analyze_modifications(original_content, final_content)
        manager.save_style_profile(scene_type, style_features)
        st.success("âœ… å†™ä½œé£æ ¼å·²æ›´æ–°")
    except: pass
    
    # 2. çŠ¶æ€ä¸è®¾å®šè‡ªåŠ¨æ›´æ–°
    with st.spinner("æ­£åœ¨åŒæ­¥è§’è‰²çŠ¶æ€ä¸ä¸–ç•Œè§‚è®¾å®š..."):
        try:
            from utils.setting_updater import analyze_and_update_settings
            analyze_and_update_settings(final_content, chapter_title)
            st.success("âœ… è§’è‰²çŠ¶æ€ä¸è®¾å®šå·²åŒæ­¥")
        except Exception as e:
            st.warning(f"è‡ªåŠ¨æ›´æ–°å¤±è´¥: {e}")
            
    st.session_state.generated_chapter = final_content
    st.session_state.pop("ai_draft", None)
    st.rerun()

# --- FUNCTION: INITIALIZATION ---
if app_mode == "åˆå§‹åŒ–":
    st.title("ğŸš€ é¡¹ç›®åˆå§‹åŒ–")
    
    col_main, col_chat = st.columns([3, 2])
    
    with col_main:
        st.markdown("### 1. åŸºç¡€ç¯å¢ƒä¸çŠ¶æ€æ–‡ä»¶")
        sub_col1, sub_col2 = st.columns(2)
        with sub_col1:
            if st.button("ğŸ› ï¸ åˆ›å»º/ä¿®å¤ç›®å½•ç»“æ„", use_container_width=True):
                created = file_manager.ensure_directories()
                if created:
                    st.success(f"å·²åˆ›å»º: {', '.join([os.path.basename(d) for d in created])}")
                else:
                    st.info("ç›®å½•ç»“æ„æ­£å¸¸ã€‚")

        with sub_col2:
            if st.button("ğŸ“ åˆå§‹åŒ–ç©ºç™½çŠ¶æ€æ–‡ä»¶", use_container_width=True):
                # Create empty JSONs if not exist
                msg = []
                if not os.path.exists(config.FILE_FORESHADOWING):
                    with open(config.FILE_FORESHADOWING, 'w', encoding='utf-8') as f:
                        json.dump([], f, ensure_ascii=False, indent=2)
                    msg.append("è®¾å®š_ä¼ç¬”.json")
                if not os.path.exists(config.FILE_CHARACTER_STATE):
                    with open(config.FILE_CHARACTER_STATE, 'w', encoding='utf-8') as f:
                        json.dump({}, f, ensure_ascii=False, indent=2) 
                    msg.append("è®¾å®š_è§’è‰²çŠ¶æ€.json")
                if msg:
                    st.success(f"å·²åˆ›å»º: {', '.join(msg)}")
                else:
                    st.info("çŠ¶æ€æ–‡ä»¶å·²å­˜åœ¨")
        
        st.divider()
        st.markdown("### 2. å…¨é‡çŠ¶æ€æå– (AI)")
        st.info("å¦‚æœæ‚¨å·²æœ‰æ­£æ–‡ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è®© AI é˜…è¯»å…¨æ–‡å¹¶è‡ªåŠ¨ç”Ÿæˆæ ¸å¿ƒçŠ¶æ€ã€‚")
        
        # æå–æ¨¡å¼é€‰æ‹©
        extraction_mode = st.radio(
            "é€‰æ‹©æå–æ¨¡å¼ï¼š",
            ["æ ‡å‡†æ¨¡å¼", "æ™ºèƒ½åˆ†æ®µæ¨¡å¼ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰"],
            index=0,
            horizontal=True
        )
        
        # çª—å£å‚æ•°è®¾ç½®
        window_size = 8000
        overlap_size = 1500
        if extraction_mode == "æ™ºèƒ½åˆ†æ®µæ¨¡å¼ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰":
            w_col1, w_col2 = st.columns(2)
            with w_col1:
                window_size = st.slider("çª—å£å¤§å°", 5000, 15000, 8000, 1000)
            with w_col2:
                overlap_size = st.slider("é‡å å¤§å°", 500, 3000, 1500, 500)
        
        if st.button("ğŸš€ å¼€å§‹å…¨é‡æå– (æ¶ˆè€— Token)", type="primary", use_container_width=True):
            current_model = st.session_state.get("DEFAULT_MODEL_NAME", None)
            full_text = ""
            chapters = context_manager.get_sorted_chapters()
            if chapters:
                for ch_path in chapters:
                    with open(ch_path, 'r', encoding='utf-8') as f:
                        full_text += f.read() + "\n\n"
            elif os.path.exists(config.FILE_MY_BODY):
                with open(config.FILE_MY_BODY, 'r', encoding='utf-8') as f:
                    full_text = f.read()
            else:
                st.error("æœªæ‰¾åˆ°æ­£æ–‡æ–‡ä»¶ï¼")
                full_text = None
                
            if full_text:
                with st.spinner("AI æ­£åœ¨æ·±åº¦æ‰«æå…¨æ–‡..."):
                    try:
                        if extraction_mode == "æ™ºèƒ½åˆ†æ®µæ¨¡å¼ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰":
                            extracted_data = smart_extractor.smart_extract_large_text(
                                full_text, model_name=current_model, 
                                window_size=window_size, overlap=overlap_size
                            )
                        else:
                            extracted_data = extractor.extract_all_from_text(full_text, model_name=current_model)
                        
                        if extracted_data:
                            st.session_state.last_extracted_data = extracted_data
                            extractor.save_extracted_data(extracted_data)
                            st.success("âœ… å…¨é‡æå–å¹¶æŒä¹…åŒ–å®Œæˆï¼")
                    except Exception as e:
                        st.error(f"æå–å¤±è´¥: {e}")

    with col_chat:
        st.markdown("### ğŸ“ èµ„æºä¸å¯¼å…¥")
        status = file_manager.check_resources_status()
        def status_tag(exists, name):
            color = "green" if exists else "red"
            icon = "âœ…" if exists else "âŒ"
            return f'<span style="color:{color}; font-weight:bold;">{icon} {name}</span>'
            
        st.markdown(f"""
        - {status_tag(status['my_body'], 'æˆ‘çš„æ­£æ–‡.txt')}
        - {status_tag(status['original'], 'å‚è€ƒåŸè‘—')}
        - {status_tag(status['sample'], 'å¤§ç¥ç´ ææ ·æœ¬')}
        """, unsafe_allow_html=True)
        
        st.divider()
        st.markdown("### ğŸ“¥ ç« èŠ‚å¯¼å…¥")
        if status['my_body']:
            if st.button("æ‰§è¡Œå•æ–‡ä»¶æ­£æ–‡æ‹†åˆ†", use_container_width=True):
                chapters = file_manager.parse_chapters(config.FILE_MY_BODY)
                if chapters:
                    saved_files = file_manager.save_chapters_to_files(chapters, config.DIR_BODY)
                    st.success(f"æˆåŠŸæ‹†åˆ†å¹¶å¯¼å…¥ {len(saved_files)} ç« ï¼")
                else:
                    st.warning("è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç« èŠ‚æ ‡é¢˜æ ¼å¼ï¼ˆå¦‚ï¼šç¬¬xç« ï¼‰ã€‚")
        
        if "last_extracted_data" in st.session_state:
            st.markdown("### ğŸ“Š æœ€è¿‘æå–é¢„è§ˆ")
            st.json(st.session_state.last_extracted_data)

# --- FUNCTION: DISCUSS SETTINGS ---
elif app_mode == "æ¢è®¨è®¾å®š":
    st.title("ğŸ§  è®¾å®šæ¢è®¨å·¥ä½œå°")
    
    # ä¸Šæ–¹ï¼šåˆ›ä½œå¯¹è¯
    st.markdown("### ğŸ’¬ åˆ›ä½œå¯¹è¯")
    chat_container = st.container(height=400)
    with chat_container:
        for msg in st.session_state.messages_settings:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
                
    if prompt := st.chat_input("è¾“å…¥ä½ çš„è®¾å®šæƒ³æ³•...", key="setting_chat_input"):
        st.session_state.messages_settings.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner("æ€è€ƒä¸­..."):
                    try:
                        full_prompt = context_manager.build_setting_discussion_prompt(f"å®Œå–„ä»¥ä¸‹è®¾å®šï¼š{prompt}")
                        current_model = st.session_state.get("DEFAULT_MODEL_NAME", None)
                        response = llm_client.generate_content(full_prompt, model_name=current_model)
                        st.markdown(response)
                        st.session_state.messages_settings.append({"role": "assistant", "content": response})
                    except Exception as e:
                        st.error(f"âŒ AIè°ƒç”¨å¤±è´¥: {str(e)}")
                        st.info("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIé…ç½®æ˜¯å¦æ­£ç¡®")
                        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {str(e)}")
                        import traceback
                        traceback.print_exc()
        st.rerun()
    
    st.divider()
    
    # ä¸‹æ–¹ï¼šè®¾å®šå·¥ä½œå°
    st.info("ğŸ’¡ **å·¥ä½œå°**ï¼šåœ¨æ­¤å¤„ç²¾ä¿®å’Œä¿å­˜ AI ç”Ÿæˆçš„è®¾å®šå†…å®¹ã€‚")
    
    # åˆå§‹åŒ–æ‹†åˆ†ç»“æœçŠ¶æ€
    if "pending_split_results" not in st.session_state:
        st.session_state.pending_split_results = None
    
    # è®¾å®šä¿å­˜åŒºåŸŸ
    if st.session_state.messages_settings:
        # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦ä¸ºAIå›å¤
        last_msg = st.session_state.messages_settings[-1]
        if last_msg["role"] != "assistant":
            st.warning("âš ï¸ è¯·å…ˆä¸AIè¿›è¡Œå¯¹è¯ï¼Œè·å¾—AIç”Ÿæˆçš„è®¾å®šå†…å®¹åå†è¿›è¡Œä¿å­˜æ“ä½œ")
            st.info("ğŸ’¡ æ“ä½œæµç¨‹ï¼š1. åœ¨ä¸Šæ–¹å¯¹è¯æ¡†è¾“å…¥è®¾å®šæƒ³æ³• â†’ 2. ç­‰å¾…AIç”Ÿæˆå›å¤ â†’ 3. åœ¨ä¸‹æ–¹ç²¾ä¿®å¹¶ä¿å­˜")
        else:
            last_response = last_msg["content"]
            user_input = st.session_state.messages_settings[-2]["content"] if len(st.session_state.messages_settings) >= 2 else "æ–°è®¾å®š"
            
            st.subheader("ğŸ“ è®¾å®šè‰ç¨¿ç²¾ä¿®")
            st.info("ğŸ“„ å½“å‰ç¼–è¾‘å†…å®¹æ¥è‡ªAIçš„å›å¤ã€‚æ‚¨å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ä¸‹æ–¹å†…å®¹ï¼Œç„¶åç‚¹å‡»æ™ºèƒ½æ‹†åˆ†é¢„è§ˆã€‚")
            
            # ä½¿ç”¨ session_state ä¿æŒç¼–è¾‘å†…å®¹ï¼Œé¿å…é¡µé¢åˆ·æ–°ä¸¢å¤±
            if "setting_editor_content" not in st.session_state or st.session_state.get("last_ai_resp_id") != id(last_response):
                st.session_state.setting_editor_content = last_response
                st.session_state.last_ai_resp_id = id(last_response)

            edited_setting = st.text_area("å†…å®¹ç¼–è¾‘", value=st.session_state.setting_editor_content, height=300, key="setting_text_area")
            st.session_state.setting_editor_content = edited_setting
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ” 1. æäº¤AIæ™ºèƒ½æ‹†åˆ†é¢„è§ˆ", type="primary", use_container_width=True):
                    with st.spinner("AIæ­£åœ¨åˆ†æå¹¶æ™ºèƒ½æ‹†åˆ†å†…å®¹..."):
                        try:
                            # å¼ºåŒ–åçš„æ‹†åˆ†æç¤ºè¯
                            split_prompt = f"""
# ä»»åŠ¡ï¼šè®¾å®šå†…å®¹ç²¾ç¡®è¯­ä¹‰æ‹†åˆ†

ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å°è¯´è®¾å®šç®¡ç†ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼Œå°†å…¶æ‹†åˆ†åˆ°å¯¹åº”çš„è®¾å®šç±»åˆ«ä¸­ã€‚

[å¾…å¤„ç†å†…å®¹ï¼ˆAIç”Ÿæˆçš„å»ºè®®/ç²¾ä¿®åçš„å†…å®¹ï¼‰]ï¼š
{edited_setting}

[å‚è€ƒèƒŒæ™¯ï¼ˆç”¨æˆ·åŸå§‹æé—®ï¼‰]ï¼š
{user_input}

[ä¸¥æ ¼åˆ†ç±»è§„èŒƒ]ï¼š
1. ä¸–ç•Œè§‚_åœ°å›¾è®¾å®šï¼šåœ°ç†ã€æ°”å€™ã€å®è§‚èƒŒæ™¯ã€‚
2. äººç‰©è®¾å®šï¼šè§’è‰²æ€§æ ¼ã€èƒŒæ™¯ã€å¤–è²Œã€‚
3. åŠ¿åŠ›_ç»„ç»‡è®¾å®šï¼šé—¨æ´¾ã€å®¶æ—ã€å›½å®¶ç»„ç»‡ã€‚
4. æˆ˜åŠ›_åŠŸæ³•è®¾å®šï¼šå¢ƒç•Œåˆ’åˆ†ã€åŠŸæ³•åç§°ã€å…·ä½“æ•ˆæœã€‚
5. ç‰©å“_é“å…·è®¾å®šï¼šæ­¦å™¨ã€ä¸¹è¯ã€å¥‡çå¼‚å®ã€‚
6. å†å²_èƒŒæ™¯è®¾å®šï¼šå†å²äº‹ä»¶ã€å¤è€ä¼ è¯´ã€æ—¶ä»£æ¼”å˜ã€‚
7. è§„åˆ™_åˆ¶åº¦è®¾å®šï¼šä¿®è¡Œé€»è¾‘ã€ç¤¾ä¼šè¿è¡Œæ³•åˆ™ã€ç¡¬æ€§é™åˆ¶ã€‚
8. å…¶ä»–ç‰¹æ®Šè®¾å®šï¼šæ— æ³•å½’å…¥ä»¥ä¸Šç±»åˆ«çš„å…¶ä»–è®¾å®šå†…å®¹ã€‚

[ç¦æ­¢äº‹é¡¹]ï¼š
- ä¸¥ç¦å­˜å…¥ç”¨æˆ·åŸå§‹æé—®çš„å†…å®¹ã€‚
- ä¸¥ç¦ç”Ÿæˆå°è¯´æ­£æ–‡ï¼ˆå¦‚ï¼š'ä»–æ‹”å‡ºåˆ€...'ï¼‰ã€‚
- ä¸¥ç¦ä¿®æ”¹åŸæ–‡çš„æ ¸å¿ƒæœ¯è¯­ã€‚
- æ¯ä¸€æ®µå†…å®¹åªèƒ½å‡ºç°åœ¨ä¸€ä¸ªç±»åˆ«ä¸­ï¼Œä¸è¦é‡å¤ã€‚
- å¦‚æœæŸç±»åˆ«æ— å†…å®¹ï¼Œè¯·ä¸è¦åŒ…å«è¯¥é”®ã€‚

è¯·ä¸¥æ ¼ä»¥æ ‡å‡†JSONæ ¼å¼è¿”å›ï¼š
{{
  "ç±»åˆ«å": "å¯¹åº”çš„è®¾å®šå†…å®¹"
}}
"""
                            current_model = st.session_state.get("DEFAULT_MODEL_NAME", None)
                            ai_response = llm_client.generate_content(split_prompt, model_name=current_model)
                            
                            # è§£æ JSON
                            import json
                            json_str = ai_response.strip()
                            if "```json" in json_str:
                                json_str = json_str.split("```json")[1].split("```")[0].strip()
                            elif "```" in json_str:
                                json_str = json_str.split("```")[1].split("```")[0].strip()
                            
                            st.session_state.pending_split_results = json.loads(json_str)
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"âŒ AIæ‹†åˆ†å¤±è´¥ï¼š{str(e)}")
                            st.session_state.pending_split_results = None

            with col2:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºé¢„è§ˆ/è‰ç¨¿", use_container_width=True):
                    st.session_state.pending_split_results = None
                    st.rerun()

            # æ‹†åˆ†ç»“æœé¢„è§ˆä¸æœ€ç»ˆç¡®è®¤
            if st.session_state.pending_split_results:
                st.markdown("### ğŸ“‹ æ‹†åˆ†é¢„è§ˆç¡®è®¤")
                st.info("ğŸ‘‡ è¯·æ ¸å¯¹ AI çš„åˆ†ç±»æ˜¯å¦å‡†ç¡®ã€‚ç¡®è®¤æ— è¯¯åç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ­£å¼å­˜å…¥è®¾å®šåº“ã€‚")
                
                for cat, content in st.session_state.pending_split_results.items():
                    with st.expander(f"ğŸ“ å½’ç±»è‡³ï¼š{cat}", expanded=True):
                        st.write(content)
                
                if st.button("âœ… 2. ç¡®è®¤æ— è¯¯ï¼Œæ­£å¼å­˜å…¥è®¾å®šåº“", type="primary", use_container_width=True):
                    try:
                        os.makedirs(config.DIR_SETTINGS, exist_ok=True)
                        saved_files = []
                        for category, content in st.session_state.pending_split_results.items():
                            if content and content.strip():
                                filename = f"è®¾å®š_{category}.txt"
                                filepath = os.path.join(config.DIR_SETTINGS, filename)
                                
                                # åŸå­åŒ–å†™å…¥é€»è¾‘ï¼šè¿½åŠ æ¨¡å¼
                                with open(filepath, 'a', encoding='utf-8') as f:
                                    f.write(f"\n=== æ›´æ–°äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                                    f.write(f"{content}\n")
                                saved_files.append(filename)
                        
                        st.success(f"âœ¨ æˆåŠŸå­˜å…¥ä»¥ä¸‹æ–‡ä»¶ï¼š{', '.join(saved_files)}")
                        st.session_state.pending_split_results = None # æ¸…ç©ºçŠ¶æ€
                        st.balloons()
                    except Exception as e:
                        st.error(f"âŒ æœ€ç»ˆä¿å­˜å¤±è´¥ï¼š{str(e)}")
    else:
        st.warning("æš‚æ— ç”Ÿæˆå†…å®¹ï¼Œè¯·åœ¨ä¸Šæ–¹ä¸ AI æ¢è®¨ã€‚")


# --- FUNCTION: DISCUSS OUTLINE ---
elif app_mode == "æ¢è®¨ç»†çº²":
    st.title("ğŸ“ ç»†çº²é€»è¾‘å»ºæ¨¡")
    
    # ä¸Šæ–¹ï¼šé€»è¾‘å»ºæ¨¡å¯¹è¯
    st.markdown("### ğŸ’¬ é€»è¾‘å»ºæ¨¡å¯¹è¯")
    chat_container = st.container(height=400)
    with chat_container:
        for msg in st.session_state.messages_outline:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
        
    if prompt := st.chat_input("è¾“å…¥å‰§æƒ…æ„æ€...", key="outline_chat_input"):
        st.session_state.messages_outline.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner("ä¸»ç¼–å»ºæ¨¡ä¸­..."):
                    try:
                        full_prompt = context_manager.build_outline_discussion_prompt(prompt)
                        current_model = st.session_state.get("DEFAULT_MODEL_NAME", None)
                        response = llm_client.generate_content(full_prompt, model_name=current_model)
                        st.markdown(response)
                        st.session_state.messages_outline.append({"role": "assistant", "content": response})
                        st.session_state.current_blueprint = response
                    except Exception as e:
                        st.error(f"âŒ AIè°ƒç”¨å¤±è´¥: {str(e)}")
                        st.info("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIé…ç½®æ˜¯å¦æ­£ç¡®")
                        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {str(e)}")
                        import traceback
                        traceback.print_exc()
        st.rerun()
    
    st.divider()
    
    # ä¸‹æ–¹ï¼šç»†çº²ç²¾ä¿®å·¥ä½œå°
    st.info("ğŸ­ **èº«ä»½ï¼šä¸»ç¼–** | ä»»åŠ¡ï¼šå°†æ„æ€è½¬åŒ–ä¸ºé«˜æµ“åº¦æ‰§è¡Œå›¾çº¸ã€‚")
    
    # ç»†çº²ç¼–è¾‘åŒº
    if "current_blueprint" not in st.session_state:
        st.session_state.current_blueprint = ""
        
    st.subheader("ğŸ› ï¸ ç»†çº²ç²¾ä¿®")
    edited_blueprint = st.text_area("æ‰§è¡Œå›¾çº¸ç¼–è¾‘å™¨", value=st.session_state.current_blueprint, height=300)
    st.session_state.current_blueprint = edited_blueprint
    
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ’¾ ä»…ä¿å­˜ç»†çº²", use_container_width=True):
            os.makedirs(config.DIR_OUTLINES, exist_ok=True)
            with open(os.path.join(config.DIR_OUTLINES, "å½“å‰ç»†çº².txt"), 'w', encoding='utf-8') as f:
                f.write(edited_blueprint)
            st.success("ç»†çº²å·²ä¿å­˜")
    with c2:
        if st.button("ğŸš€ ç¡®è®¤å¹¶å‰å¾€ç»­å†™", type="primary", use_container_width=True):
            os.makedirs(config.DIR_OUTLINES, exist_ok=True)
            with open(os.path.join(config.DIR_OUTLINES, "å½“å‰ç»†çº².txt"), 'w', encoding='utf-8') as f:
                f.write(edited_blueprint)
            st.session_state["app_mode_switch"] = "ç»­å†™æ­£æ–‡"
            st.rerun()

# --- FUNCTION: WRITE BODY ---
elif app_mode == "ç»­å†™æ­£æ–‡":
    st.title("âœï¸ ç»­å†™æ­£æ–‡å·¥ä½œå°")
    col_main, col_chat = st.columns([3, 2])
    
    with col_main:
        # åŠ è½½ç»†çº²
        outline_path = os.path.join(config.DIR_OUTLINES, "å½“å‰ç»†çº².txt")
        outline_content = ""
        if os.path.exists(outline_path):
            with open(outline_path, 'r', encoding='utf-8') as f:
                outline_content = f.read()
        
        st.subheader("ğŸ“œ å½“å‰å‚è€ƒç»†çº²")
        user_outline = st.text_area("ç»†çº²å†…å®¹ (å¯å®æ—¶è°ƒæ•´)", outline_content, height=200)
        
        if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆæ­£æ–‡", type="primary", use_container_width=True):
            with st.spinner("æé“æµæ–‡é£æ³¨å…¥ä¸­ï¼Œæ­£åœ¨æ’°å†™..."):
                # è‡ªåŠ¨åŠ è½½æ–‡é£
                full_prompt = context_manager.build_context_prompt(
                    f"è¯·æ ¹æ®ä»¥ä¸‹ç»†çº²ç»­å†™å°è¯´æ­£æ–‡ï¼Œä¸¥æ ¼æ¨¡ä»¿æ–‡é£ç´ æï¼š\n\n{user_outline}",
                    include_style=True
                )
                current_model = st.session_state.get("DEFAULT_MODEL_NAME", None)
                generated_text = llm_client.generate_content(full_prompt, model_name=current_model)
                st.session_state.generated_chapter = generated_text
                st.session_state.ai_draft = generated_text  # æ–°å¢ï¼šé”å®šåŸå§‹è‰ç¨¿ä½œä¸ºé£æ ¼å¯¹æ¯”åŸºå‡†
                st.rerun()

        if 'generated_chapter' in st.session_state:
            st.subheader("ğŸ–‹ï¸ æ­£æ–‡ç²¾ä¿®")
            # æ³¨æ„ï¼šæ­¤å¤„ä¸ç›´æ¥åŒæ­¥å› generated_chapterï¼Œç›´åˆ°ç‚¹å‡»ä¿å­˜
            final_content = st.text_area("æ­£æ–‡ç¼–è¾‘å™¨", st.session_state.generated_chapter, height=500)
            
            c1, c2, c3, c4 = st.columns([2, 1, 1, 1])
            with c1:
                chapter_title = st.text_input("ç« èŠ‚æ–‡ä»¶å", placeholder="ç¬¬xç«  æ¿€æˆ˜.txt")
            with c2:
                if st.button("ğŸ’¾ ä»…ä¿å­˜ç« èŠ‚", use_container_width=True):
                    if chapter_title:
                        if not chapter_title.endswith(".txt"): chapter_title += ".txt"
                        save_path = os.path.join(config.DIR_BODY, chapter_title)
                        with open(save_path, 'w', encoding='utf-8') as f:
                            f.write(final_content)
                        st.session_state.generated_chapter = final_content # ä¿å­˜æ—¶æ›´æ–°çŠ¶æ€
                        st.success(f"âœ… ç« èŠ‚å·²ä¿å­˜: {chapter_title}")
                    else:
                        st.error("è¯·è¾“å…¥æ–‡ä»¶å")
            with c3:
                if st.button("ğŸ’¾ ä¿å­˜å¹¶åˆ†æé£æ ¼", use_container_width=True):
                    if chapter_title:
                        # ä½¿ç”¨ ai_draft è¿›è¡Œå¯¹æ¯”
                        original = st.session_state.get("ai_draft", final_content)
                        _save_with_style_analysis_v2(chapter_title, final_content, original)
                    else:
                        st.error("è¯·è¾“å…¥æ–‡ä»¶å")
            with c4:
                if st.button("ğŸ’¾ å…¨éƒ¨åŠŸèƒ½", type="primary", use_container_width=True):
                    if chapter_title:
                        original = st.session_state.get("ai_draft", final_content)
                        _save_with_full_features_v2(chapter_title, final_content, original)
                    else:
                        st.error("è¯·è¾“å…¥æ–‡ä»¶å")

    with col_chat:
        st.markdown("### ğŸ§  å†™ä½œè¾…åŠ©")
        with st.expander("ğŸ“ ç»†çº²è¦ç‚¹å›é¡¾", expanded=True):
            st.markdown(user_outline)
        
        with st.expander("ğŸ¨ æ–‡é£è‡ªåŠ¨æŒ‡çº¹", expanded=False):
            style_info = context_manager.auto_style_loader()
            if style_info:
                st.markdown(style_info)
            else:
                st.info("assets/ æ–‡ä»¶å¤¹ä¸‹æœªæ£€æµ‹åˆ°æ–‡é£ç´ æã€‚")

# --- FUNCTION: MODIFY & CONFLICT ---
elif app_mode == "æ”¹æ–‡ä¸å†²çªæç¤º":
    st.title("ğŸ” æ”¹æ–‡ä¸å†²çªå®¡è®¡")
    col_main, col_chat = st.columns([3, 2])
    
    with col_main:
        files = context_manager.get_sorted_chapters()
        file_names = [os.path.basename(f) for f in files]
        
        if not file_names:
            st.warning("æš‚æ— æ­£æ–‡ç« èŠ‚ã€‚")
        else:
            selected_file = st.selectbox("é€‰æ‹©è¦å®¡è®¡çš„ç« èŠ‚", file_names)
            file_path = os.path.join(config.DIR_BODY, selected_file)
            
            if 'current_editing_file' not in st.session_state or st.session_state.current_editing_file != selected_file:
                with open(file_path, 'r', encoding='utf-8') as f:
                    st.session_state.current_content = f.read()
                st.session_state.original_content = st.session_state.current_content
                st.session_state.current_editing_file = selected_file
            
            new_content = st.text_area("æ­£æ–‡å®¡è®¡ç¼–è¾‘å™¨", st.session_state.current_content, height=600)
            
            if st.button("ğŸ’¾ ä¿å­˜å¹¶æ‰§è¡Œå†²çªæ‰«æ", type="primary", use_container_width=True):
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                removed_terms = text_analyzer.get_text_diff(st.session_state.original_content, new_content)
                removed_terms = [t.strip() for t in removed_terms if len(t.strip()) > 1]
                
                st.session_state.audit_results = {
                    "removed": removed_terms,
                    "conflicts": text_analyzer.scan_chapters_for_conflict(removed_terms, file_names.index(selected_file), files) if removed_terms else {}
                }
                st.session_state.current_content = new_content
                st.session_state.original_content = new_content
                st.rerun()

    with col_chat:
        st.markdown("### âš ï¸ å†²çªå®¡è®¡æŠ¥å‘Š")
        if "audit_results" in st.session_state:
            res = st.session_state.audit_results
            if res["removed"]:
                st.warning(f"æ£€æµ‹åˆ°å…³é”®åˆ æ”¹: {', '.join(res['removed'])}")
                if res["conflicts"]:
                    st.error("å‘ç°æ½œåœ¨å› æœå†²çªï¼š")
                    for fname, terms in res["conflicts"].items():
                        st.markdown(f"- **{fname}**: æ¶‰åŠ `{', '.join(terms)}`")
                else:
                    st.success("åç»­ç« èŠ‚æœªå‘ç°æ–‡æœ¬å±‚é¢çš„ç›´æ¥å†²çªã€‚")
            else:
                st.info("æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„å…³é”®è¯åˆ é™¤ã€‚")
        else:
            st.info("è¯·åœ¨å·¦ä¾§ç‚¹å‡»ä¿å­˜å¹¶æ‰§è¡Œå®¡è®¡ã€‚")
        
        st.divider()
        if st.button("ğŸ¤– AI æ·±åº¦åˆ†ææœ¬ç« ä¼ç¬”å˜åŠ¨", use_container_width=True):
            if 'current_content' in st.session_state:
                with st.spinner("æ­£åœ¨åˆ†æå› æœé“¾..."):
                    # ç®€åŒ–åˆ†æé€»è¾‘
                    prompt = f"åˆ†ææ­¤ç« èŠ‚å¯¹ä¼ç¬”å’ŒçŠ¶æ€çš„å½±å“ï¼š\n\n{st.session_state.current_content[:5000]}"
                    current_model = st.session_state.get("DEFAULT_MODEL_NAME", None)
                    analysis = llm_client.generate_content(prompt, model_name=current_model)
                    st.markdown(analysis)